import logging
import os

from dotenv import load_dotenv
from openaillm import OpenAILLM, RAGConfig

import gradio as gr
from gradio.themes.base import Base


def main() -> None:
    logging.basicConfig(format='%(asctime)s - %(message)s', level=logging.INFO)
    load_dotenv()
    rag_config = RAGConfig(
        index_name='openai_idx',
        db_name='langchain_demo',
        collection_name='collection_of_blobs',
        openai_api_key=os.getenv('OPENAI_API_KEY'),
        mongo_uri=os.getenv('MONGO_DB_URI'),
    )
    openai_llm = OpenAILLM(config=rag_config)
    with gr.Blocks(theme=Base(), title="RAG Presentation") as demo:
        gr.Markdown(
            """
            #  Atlas Vector Search + RAG Architecture + OpenAI
            """)
        textbox = gr.Textbox(label="Enter your Question:")
        with gr.Row():
            button = gr.Button("Submit", variant="primary")
        with gr.Column():
            output1 = gr.Textbox(lines=1, max_lines=10,
                                 label="Output with just Atlas Vector Search (returns text field as is):")
            output2 = gr.Textbox(lines=1, max_lines=10,
                                 label="Output generated by chaining Atlas Vector Search to Langchain's RetrieverQA + OpenAI LLM:")

        # Call query_data function upon clicking the Submit button

        button.click(openai_llm.answer, textbox, outputs=[output1, output2])

    demo.launch()


if __name__ == '__main__':
    main()
